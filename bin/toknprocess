#!/usr/bin/env ruby

# Given a compiled DFA file and a source file,
# extract all tokens from the source file.
#
# Example usage (for Unix); assumes tokncompile.rb
# has been run beforehand:
#
#
# toknprocess dfa.txt sampletext.txt
#

require 'tokn/compiler'

include Tokn

if ARGV.size < 2 || ARGV.size > 3
  puts "Usage: toknprocess <dfa file> <source file> [<skip token name>]"
  abort
end


compiled_dfa = File.read(ARGV[0])
dfa = DFA.from_json(compiled_dfa)
skipName = nil
if ARGV.size >= 3
	skipName = ARGV[2]
end

tk = Tokenizer.new(dfa, File.read(ARGV[1]), skipName)

while tk.has_next
  t = tk.read
  printf("%s %d %d %s\n",tk.name_of(t),t.line_number,t.column,t.text)
end
