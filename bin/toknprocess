#!/usr/bin/env ruby

# Given a compiled DFA file and a source file,
# extract all tokens from the source file.
#
# Example usage (for Unix); assumes tokncompile.rb
# has been run beforehand:
#
#
# toknprocess dfa.txt sampletext.txt
#

require_relative '../lib/tokn/compiler/tokn_compiler'
require 'js_base'

include Tokn

if ARGV.size < 2 || ARGV.size > 3
  puts "Usage: toknprocess <dfa file> <source file> [<skip token name>]"
  abort
end


compiled_dfa = FileUtils.read_text_file(ARGV[0])
dfa = DFA.from_json(compiled_dfa)
skipName = nil
if ARGV.size >= 3
	skipName = ARGV[2]
end

tk = Tokenizer.new(dfa, FileUtils.read_text_file(ARGV[1]), skipName)

while tk.has_next
  t = tk.read
  printf("%s %d %d %s\n",tk.name_of(t),t.lineNumber,t.column,t.text)
end
